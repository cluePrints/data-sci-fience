{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "from lxml import html\n",
    "from lxml import etree\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def identify_letter_urls(blog_url):\n",
    "    response = requests.get(blog_url)\n",
    "    tree = html.fromstring(response.content)\n",
    "    hrefs = tree.xpath('//dt[@class=\"entry-title\"]/a[@class=\"subj-link\"]')\n",
    "    hrefs = filter(lambda href: href.text.startswith(\"Письмо.\"), hrefs)\n",
    "    pages_to_visit = map(lambda href: href.get('href'), hrefs)\n",
    "    return list(pages_to_visit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pages_to_visit = identify_letter_urls(\"https://evo-lutio.livejournal.com/?tag=evolutiolab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_letter(post_url):\n",
    "    response = requests.get(post_url)\n",
    "    tree = html.fromstring(response.content)\n",
    "    article = tree.xpath('//div[@class=\"b-singlepost-bodywrapper\"]/article')[0]\n",
    "    lj_authors = article.xpath(\"span/a/b/text()\")\n",
    "    lj_author = str(lj_authors[0])\n",
    "    lj_author2 = str(lj_authors[1]) if len(lj_authors) > 1 else None\n",
    "\n",
    "    lj_author_cited = False\n",
    "    text = u''\n",
    "    for el in article.itertext():\n",
    "        element_text = str(el)\n",
    "        if (element_text == lj_author2):\n",
    "            return text\n",
    "        if (element_text == lj_author):\n",
    "            lj_author_cited = True\n",
    "            continue\n",
    "        if (not lj_author_cited):\n",
    "            continue\n",
    "        if (element_text.startswith(\"(\")):\n",
    "            continue\n",
    "        text += element_text + '\\n'\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 46 letter urls now\n",
      "Got 81 letter urls now\n",
      "Got 120 letter urls now\n",
      "Got 160 letter urls now\n",
      "Got 195 letter urls now\n",
      "Got 229 letter urls now\n",
      "Got 264 letter urls now\n",
      "Got 300 letter urls now\n",
      "Got 333 letter urls now\n",
      "Got 356 letter urls now\n",
      "Stuck at page 10 quitting\n"
     ]
    }
   ],
   "source": [
    "from sets import Set\n",
    "delta = 40\n",
    "letter_urls = Set()\n",
    "for page in range(0, 20):\n",
    "    prev_size = len(letter_urls)\n",
    "    letter_urls.update(Set(identify_letter_urls(\"https://evo-lutio.livejournal.com/?tag=evolutiolab&skip=\" + str(delta*page))))\n",
    "    if (prev_size == len(letter_urls)):\n",
    "        print(\"Stuck at page \" + str(page) + \" quitting\")\n",
    "        break;\n",
    "    else:\n",
    "        print(\"Got \" + str(len(letter_urls)) + \" letter urls now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mkdir -p letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "letter_urls = list(letter_urls)\n",
    "f = open(\"letter_urls.txt\", \"w\")\n",
    "f.write(\"\\n\".join(map(lambda x: str(x), letter_urls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter #567581 already extracted - skipping\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "for letter_url in letter_urls:\n",
    "    letter_id = re.findall(\"([0-9]+).html\", letter_url)[0]\n",
    "    letter_path = \"letters/{letter_id}.txt\".format(letter_id=letter_id)\n",
    "    if (os.path.exists(letter_path)):\n",
    "        print(\"Letter #{letter_id} already extracted - skipping\".format(letter_id=letter_id))\n",
    "        continue\n",
    "\n",
    "    letter_text = extract_letter(letter_url)\n",
    "    with open(letter_path, \"w\") as f:        \n",
    "        f.write(letter_text)\n",
    "    \n",
    "    print(\"Extracted letter {letter_id}: {length} length\".format(letter_id=letter_id, length=len(letter_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0M\tletters\r\n"
     ]
    }
   ],
   "source": [
    "!du -hs letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318972.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls letters | head -n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_text = '';\n",
    "for fname in os.listdir(\"letters\"):\n",
    "    with open('letters/'+fname, 'r') as f:\n",
    "        all_text += f.read() + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(all_text)))\n",
    "chars.insert(0, '\\0')\n",
    "vocab_size = len(chars)\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = [char_indices[c] for c in all_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5501573"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('nb sequences:', 5501534)\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(idx) - maxlen+1):\n",
    "    sentences.append(idx[i: i + maxlen])\n",
    "    next_chars.append(idx[i+1: i+maxlen+1])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = np.concatenate([[np.array(o)] for o in sentences[:-2]])\n",
    "next_chars = np.concatenate([[np.array(o)] for o in next_chars[:-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5501532, 40), (5501532, 40))"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sentences.shape, next_chars.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences_sample = sentences[0:50000]\n",
    "next_chars_sample = next_chars[0:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dropout, LSTM, TimeDistributed, Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=maxlen),\n",
    "        LSTM(512, input_dim=n_fac,return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        LSTM(512, return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size)),\n",
    "        Activation('softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 209s - loss: 1.7503   \n",
      "CPU times: user 2min 49s, sys: 1min 8s, total: 3min 58s\n",
      "Wall time: 4min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f63695aad90>"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model.fit(sentences_sample, np.expand_dims(next_chars_sample,-1), batch_size=64, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 121s - loss: 1.7616   \n",
      "CPU times: user 1min 54s, sys: 30.8 s, total: 2min 24s\n",
      "Wall time: 2min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f634bd73cd0>"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consume_less=gpu reports to have spent less time = 119s vs 209s :/\n",
    "%time model.fit(sentences_sample, np.expand_dims(next_chars_sample,-1), batch_size=64, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Здравствуйте, Эволюция. Меньлаяя воске кеч кат тастµ эиешрвоне. В. - Но бяде пореду вемя и сет, на не мвемелсев мкуш. Отта, ч иебще негил, Оща тов- Повваленая что друго² простривужае ом буму. � Я мве фомом\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import choice\n",
    "def print_example():\n",
    "    seed_string=\"Здравствуйте, Эволюция.\"\n",
    "    for i in range(320):\n",
    "        try:\n",
    "            x=np.array([char_indices[c] for c in seed_string[-40:]])[np.newaxis,:]\n",
    "            preds = model.predict(x, verbose=0)[0][-1]\n",
    "            preds = preds/np.sum(preds)\n",
    "            next_char = choice(chars, p=preds)\n",
    "            seed_string = seed_string + next_char\n",
    "        except:            \n",
    "            print(\"X \" + str(x.shape))\n",
    "            print(\"Preds \" + str(len(preds)))\n",
    "            print(\"Chars \" + str(len(chars)))\n",
    "            print(\"i \" + str(i))\n",
    "            raise\n",
    "    print(seed_string)\n",
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 121s - loss: 1.2714   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f63495d8050>"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences_sample, np.expand_dims(next_chars_sample,-1), batch_size=64, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Здравствуйте, Эволюция.\n",
      "На стал я у меня :Чыхор ен сельа бод не хаз кела ток гомуше и не нав денерения опять лоторого вв сраси ра на хотиения в иехил «дс. Вень.\n",
      "У пусно полилалым. Он ходло рямы, жажесклу�\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 121s - loss: 1.0868   \n",
      "Здравствуйте, Эволюция.\n",
      "Потьпить с антересный невелю. Нет, так? На тро «не опять прямшопе рыла мы симьмились, и остраницуся. . \n",
      "\n",
      " Чсастая что ответила сне, лак-м не раз иткатил, чтосут кад это не довегще �\n"
     ]
    }
   ],
   "source": [
    "model.fit(sentences_sample, np.expand_dims(next_chars_sample,-1), batch_size=64, nb_epoch=1)\n",
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 121s - loss: 0.9418   \n",
      "Здравствуйте, Эволюция.\n",
      "Про себя (мне 23, едс находили увобо умадал, я его дат-иние, написал что мружым снова в понр-дения по ваю другую с денте объеки в лаписала воздух Притивинось, тебя пришло!\n",
      "Простил\n"
     ]
    }
   ],
   "source": [
    "model.fit(sentences_sample, np.expand_dims(next_chars_sample,-1), batch_size=64, nb_epoch=1)\n",
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 121s - loss: 0.8359   \n",
      "Здравствуйте, Эволюция.\n",
      "\n",
      "Ссе это были понять встречи, антерес с упать с ним бы вышла не умержёю помучтились встретиться ,же мосяца вообще она извинее не ответила. Через неша обо родиловала пок-ли все �\n"
     ]
    }
   ],
   "source": [
    "model.fit(sentences_sample, np.expand_dims(next_chars_sample,-1), batch_size=64, nb_epoch=1)\n",
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 121s - loss: 0.7554   \n",
      "Здравствуйте, Эволюция.\n",
      "Сечером заерал привдах потом стал ла приедет своджели домой и все –такие нет, говорили комплиментов. На привело переписывался на разу. \n",
      "Я нипрадямать?\n",
      "-Волчал по жимнье дела» \n"
     ]
    }
   ],
   "source": [
    "model.fit(sentences_sample, np.expand_dims(next_chars_sample,-1), batch_size=64, nb_epoch=1)\n",
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 111s - loss: 0.6865 - val_loss: 0.7039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6350b9b790>"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences_sample, np.expand_dims(next_chars_sample,-1), batch_size=64, nb_epoch=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Здравствуйте, Эволюция.\n",
      "\n",
      "Извиняться вечером 9го, познакомились и ушла. Да и все ответила. Разводиться, когда я не реагились е возде другую ком того в зафе. На помторится, когда от мужем потом заехал на �\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5226455 samples, validate on 275077 samples\n",
      "Epoch 1/1\n",
      "  45504/5226455 [..............................] - ETA: 12528s - loss: 1.1562"
     ]
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, nb_epoch=1, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
