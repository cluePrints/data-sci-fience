{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "total_text_length = 0\n",
    "letters = [];\n",
    "for fname in os.listdir(\"letters\"):\n",
    "    with open('letters/'+fname, 'r') as f:\n",
    "        letter = f.read().decode(\"utf-8\")\n",
    "        total_text_length += len(letter)\n",
    "        letters += [letter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добрый день, Эволоция. Я пишу письмо в рубрику, чтобы разобраться в себе – правильно ли я делаю, что\n"
     ]
    }
   ],
   "source": [
    "print(letters[0][0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "земной\n",
      "атомной\n",
      "мной\n",
      "автономной\n",
      "огромной\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# wget https://www.dropbox.com/s/0x7oxso6x93efzj/ru.tar.gz?dl=0 -O ru_Kyubyong_fasttext.tar.gz\n",
    "# stemming is not needed - words there seem to be in the original form\n",
    "\n",
    "grep мной ru.vec | cut '-d ' -f1 |head -n5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "text = \"Красивая мама, красиво мыла раму\"\n",
    "def tokenize(text, m = Mystem()):    \n",
    "    analysis = m.analyze(text)\n",
    "    return [e['text'] for e in analysis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:1: DeprecationWarning: the sets module is deprecated\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "from sets import Set\n",
    "all_tokens = Set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 ms, sys: 4 ms, total: 12 ms\n",
      "Wall time: 977 ms\n"
     ]
    }
   ],
   "source": [
    "%time tokens = tokenize(letters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "analysis = m.analyze(letters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5065"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(letters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1707"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_tokens.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "from lxml import html\n",
    "from lxml import etree\n",
    "from IPython.display import display\n",
    "from ipywidgets import IntProgress\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "progress = IntProgress(min=0, max=len(letters), value=0)\n",
    "display(progress)\n",
    "LETTER_END = '\\0'\n",
    "tokenized_text = []\n",
    "for letter in letters:\n",
    "    tokenized_text += tokenize(letter)\n",
    "    tokenized_text += [LETTER_END]\n",
    "    progress.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tokens = Set(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1037419, 45689)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(tokenized_text), len(all_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary = sorted(list(all_tokens))\n",
    "vocabulary.insert(0, LETTER_END)\n",
    "token_indices = dict((c, i) for i, c in enumerate(vocabulary))\n",
    "tokens_by_index = dict((i, c) for i, c in enumerate(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_indices_lower = dict((c.lower(), i) for i, c in enumerate(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6576"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_indices_lower['баг'.decode('utf-8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_as_token_indexes = [token_indices[token] for token in tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_training_data(text_as_token_indexes, maxlen = 10):\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "    for i in range(0, len(text_as_token_indexes) - maxlen+1):\n",
    "        sentences.append(text_as_token_indexes[i: i + maxlen])\n",
    "        next_chars.append(text_as_token_indexes[i+1: i+maxlen+1])\n",
    "    print('nb sequences:', len(sentences))\n",
    "    sentences = np.concatenate([[np.array(o)] for o in sentences[:-2]])\n",
    "    next_chars = np.concatenate([[np.array(o)] for o in next_chars[:-2]])\n",
    "    return sentences, next_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences, next_chars = prepare_training_data(text_as_token_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1037408, 10), (1037408, 10))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sentences.shape, next_chars.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences_sample = sentences[0:10000]\n",
    "next_chars_sample = next_chars[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocabulary)\n",
    "n_fact = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mystem = Mystem()\n",
    "#token, index = next(token_indices.iteritems())\n",
    "#mystem.lemmatize(token)\n",
    "#[myste for token, index in all_tokens.iteritems()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(token_indices,           open('token_indices.pkl', 'w'))\n",
    "pickle.dump(token_indices_lower,     open('token_indices_lower.pkl', 'w'))\n",
    "pickle.dump(vocabulary,              open('vocabulary.pkl', 'w'))\n",
    "pickle.dump(tokens_by_index,         open('tokens_by_index.pkl', 'w'))\n",
    "pickle.dump(token_indices_lower,     open('token_indices_lower.pkl', 'w'))\n",
    "pickle.dump(text_as_token_indexes,   open('text_as_token_indexes.pkl', 'w'))\n",
    "pickle.dump(sentences,               open('sentences.pkl', 'w'))\n",
    "pickle.dump(next_chars,              open('next_chars.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7910"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_indices['в'.decode('utf-8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vector_by_token=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "from numpy import random\n",
    "vector_by_token_lower = dict()\n",
    "with open('ru.vec', 'r') as fp:\n",
    "    firstline = fp.readline()\n",
    "    count = int(firstline.split(' ')[0])\n",
    "    vocab_progress = IntProgress(min=0, max=vocab_size, value=0)\n",
    "    display(vocab_progress)\n",
    "    progress = IntProgress(min=0, max=count, value=0)\n",
    "    display(progress)\n",
    "    for cnt, line in enumerate(fp):\n",
    "        split = line.split(' ')\n",
    "        token_lower = split[0].decode('utf-8')\n",
    "        vec = np.array(map(float, split[1:301]))\n",
    "        progress.value += 1\n",
    "        if (token_lower in token_indices_lower):\n",
    "            vector_by_token_lower[token_lower] = vec\n",
    "            vocab_progress.value += 1\n",
    "        else:\n",
    "            # some word we haven't encountered in the corpuse we analyze\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50103"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15676"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector_by_token_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15676"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector_by_token_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45690"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27337"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmatched_words = list(filter(lambda word: not word.lower() in vector_by_token_lower, vocabulary))\n",
    "len(unmatched_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5983147297001532"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# russian is difficult :/\n",
    "len(unmatched_words)/float(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36548376188432374"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# russian is super difficult :/\n",
    "unmatched_text = list(filter(lambda word: not word.lower() in vector_by_token_lower, tokenized_text))\n",
    "unmatched_text_word_lengths = map(lambda word: len(word), unmatched_text) \n",
    "unmatched_text_len = reduce(lambda x,y: x+y, unmatched_text_word_lengths)\n",
    "unmatched_text_len / float(total_text_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Плачу\n",
      "Плыла\n",
      "Плюсом\n",
      "Плюсы\n",
      "Плющихе\n"
     ]
    }
   ],
   "source": [
    "for word in unmatched_words[2000:2005]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matched_words = list(Set(vocabulary) - Set(unmatched_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Следующие,Следующий,Следующим,Следующую,Слезы\n"
     ]
    }
   ],
   "source": [
    "print(','.join(vocabulary[5000:5005]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vector_by_token_idx = dict([(token_indices_lower[word.lower()], vector_by_token_lower[word.lower()]) for word in matched_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(vector_by_token_idx,              open('vector_by_token_idx.pkl', 'w'))\n",
    "pickle.dump(tokens_by_token_lower,            open('tokens_by_token_lower.pkl', 'w'))\n",
    "pickle.dump(unmatched_text,                   open('unmatched_text.pkl', 'w'))\n",
    "pickle.dump(matched_words,                    open('matched_words.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(vector_by_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "token_indices_lower['он'.decode('utf-8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "analysis = m.analyze('Помощью Полигамен Помоги Прокачивать')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(analysis[0]['analysis'][0]['lex'])\n",
    "print(analysis[2]['analysis'][0]['lex'])\n",
    "print(analysis[4]['analysis'][0]['lex'])\n",
    "print(analysis[6]['analysis'][0]['lex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_embedding(token_indices, vocab_size, n_fact):\n",
    "    import numpy as np\n",
    "    emb = np.zeros((vocab_size, n_fact))\n",
    "    for word, i in enumerate(token_indices.iteritems()):\n",
    "        token_idx = token_indices[word]\n",
    "        if not idx in vector_by_token_idx:\n",
    "            vector_by_token_idx[idx] = np.random.randn(n_fact)\n",
    "        emb[i] = vector_by_token_idx[idx]   \n",
    "        \n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45690, 300)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45690"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45690, 300, 10)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(vocab_size, n_fact, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#emb = pickle.load(open('emb.pkl', 'r'))\n",
    "#vocab_size = emb.shape[0]\n",
    "#_fact = emb.shape[1]\n",
    "#maxlen = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Embedding, Dropout, LSTM, TimeDistributed, Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fact, input_length=maxlen, dropout=0.2, weights=[emb], trainable=False),\n",
    "        LSTM(512, input_dim=n_fact,return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        LSTM(512, return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size)),\n",
    "        Activation('softmax')\n",
    "    ])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "9000/9000 [==============================] - 48s - loss: 5.1164 - val_loss: 5.6962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2d1d857590>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we did overfit even on sample - mb having more data will help :/\n",
    "model.fit(sentences_sample, np.expand_dims(next_chars_sample,-1), batch_size=512, nb_epoch=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train on 933667 samples, validate on 103741 samples\n",
    "#Epoch 1/1\n",
    "#933667/933667 [==============================] - 5034s - loss: 5.2230 - val_loss: 5.1568\n",
    "#Добрый день, Эволюция ! ! Сталапоставилвключаю я половинууши\n",
    "#Train on 933667 samples, validate on 103741 samples\n",
    "#for i in range(0,10):\n",
    "#    model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=512, nb_epoch=1, validation_split=0.1)\n",
    "#    print_sample()\n",
    "#    model.save_weights('evo_vec_rnn_%s.h5' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Embedding, Dropout, LSTM, TimeDistributed, Dense, Activation, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model_bn=Sequential([\n",
    "        Embedding(vocab_size, n_fact, input_length=maxlen, dropout=0.2, weights=[emb], trainable=False),\n",
    "        LSTM(512, input_dim=n_fact,return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        LSTM(512, return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size)),\n",
    "        Activation('softmax')\n",
    "    ])\n",
    "model_bn.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "9000/9000 [==============================] - 58s - loss: 10.6167 - val_loss: 10.4305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ca2a18d90>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare this to\n",
    "# 9000/9000 [==============================] - 48s - loss: 5.1164 - val_loss: 5.6962\n",
    "# (though batch of 512 could be accomodated)\n",
    "model_bn.fit(sentences_sample, np.expand_dims(next_chars_sample,-1), batch_size=256, nb_epoch=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_bn.fit(sentences, np.expand_dims(next_chars,-1), batch_size=512, nb_epoch=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(emb, open('emb.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save_weights('evo_vec_rnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_index_frequencies = np.bincount(text_as_token_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_indices[' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394920"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_index_frequencies[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "vocabulary_sizes = []\n",
    "explained_text = []\n",
    "for frequency_threshold in range(0, 100):\n",
    "    thresholded_frequencies = filter(lambda c: c>frequency_threshold, text_index_frequencies)\n",
    "    explained_pct = np.sum(thresholded_frequencies)/float(np.sum(text_index_frequencies))\n",
    "    vocabulary_size_pct = np.count_nonzero(thresholded_frequencies)/float(len(vocabulary))\n",
    "    vocabulary_sizes.add(vocabulary_size_pct)\n",
    "    explained_text.append(explained_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2ca0a082d0>]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFkCAYAAACjCwibAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ4MkScrK/wf8KwqhCOIxlgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2ca0a080d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(0,100), vocabulary_sizes)\n",
    "plt.plot(range(0,100), explained_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def with_infrequent_elements_removed(text_as_token_indexes, threshold, replacement_index):\n",
    "    text_index_frequencies = np.bincount(text_as_token_indexes)\n",
    "    is_frequent_idx = np.greater(text_index_frequencies, threshold)\n",
    "    new_vocab_size = np.count_nonzero(np.greater(text_index_frequencies, threshold))\n",
    "    old_indexes_filtered = np.where(is_frequent_idx, np.arange(len(is_frequent_idx)), replacement_index)\n",
    "    old_indexes_by_new_indexes = np.unique(old_indexes_filtered)\n",
    "    new_indexes_by_old_indexes = dict([(old, i) for i, old in enumerate(old_indexes_by_new_indexes)])\n",
    "\n",
    "    filtered_remapped_text = np.array([new_indexes_by_old_indexes[idx] if idx in new_indexes_by_old_indexes else replacement_index for idx in text_as_token_indexes])\n",
    "    return filtered_remapped_text, new_indexes_by_old_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "INFREQUENT_ELEMENT = 0\n",
    "filtered_remapped_text, new_indexes = with_infrequent_elements_removed(text_as_token_indexes, 20, INFREQUENT_ELEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\x00', 0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_by_index[INFREQUENT_ELEMENT], text_index_frequencies[INFREQUENT_ELEMENT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2534"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(filtered_remapped_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(np.unique(filtered_remapped_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_indexes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x00'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_by_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INFREQUENT_ELEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_token_indices = dict([(t, new_indexes[i] if i in new_indexes else INFREQUENT_ELEMENT) for t,i in token_indices.iteritems()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_tokens_by_index = dict([(i,t) for t,i in filtered_token_indices.iteritems()])\n",
    "# we have multiple things in our list replaced, let's be sure this is maintained by the right element\n",
    "filtered_tokens_by_index[INFREQUENT_ELEMENT] = tokens_by_index[INFREQUENT_ELEMENT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "поинтересней\n"
     ]
    }
   ],
   "source": [
    "print(filtered_tokens_by_index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_vocabulary = [filtered_tokens_by_index[i] for i in range(0, vocab_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "поинтересней\n"
     ]
    }
   ],
   "source": [
    "print(filtered_vocabulary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEst\n"
     ]
    }
   ],
   "source": [
    "print(\"TEst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_vector_by_token_idx = dict([(new_indexes[i] if i in new_indexes else INFREQUENT_ELEMENT, v) for i, v in vector_by_token_idx.iteritems()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "emb = np.zeros((vocab_size, n_fact))\n",
    "for word, i in filtered_token_indices.iteritems():\n",
    "    token_idx = filtered_token_indices[word]\n",
    "    if not token_idx in filtered_vector_by_token_idx:\n",
    "        filtered_vector_by_token_idx[token_idx] = np.random.randn(n_fact)\n",
    "    emb[i] = filtered_vector_by_token_idx[token_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2534, 300), 2534, 300)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape, vocab_size, n_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('nb sequences:', 1037410)\n"
     ]
    }
   ],
   "source": [
    "sentences, next_chars = prepare_training_data(filtered_remapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Embedding, Dropout, LSTM, TimeDistributed, Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "maxlen = 10\n",
    "\n",
    "model_filtered=Sequential([\n",
    "        Embedding(vocab_size, n_fact, input_length=maxlen, dropout=0.2, weights=[emb], trainable=False),\n",
    "        LSTM(512, input_dim=n_fact,return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        LSTM(512, return_sequences=True, dropout_U=0.2, dropout_W=0.2,\n",
    "             consume_less='gpu'),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size)),\n",
    "        Activation('softmax')\n",
    "    ])\n",
    "model_filtered.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "9000/9000 [==============================] - 5s - loss: 5.4032 - val_loss: 4.2396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fae9780dc10>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reducing vocabulary seem to speed up the process quite a bit\n",
    "# compare this to \n",
    "# 9000/9000 [==============================] - 48s - loss: 5.1164 - val_loss: 5.6962\n",
    "model_filtered.fit(sentences[0:10000], np.expand_dims(next_chars[0:10000],-1), batch_size=512, nb_epoch=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добрый день, Эволюция ! !Вот и позвал, я не могла бы отвлечься. Но я молчала. Так он чувствовала, что я хочу терять её потерять в чем, что мы поехали вместе, кино предлагал Написал как до свадьбы мы на себя жили вместе и в основном!то: она точно слишком классно, играет, купил \n"
     ]
    }
   ],
   "source": [
    "from numpy.random import choice\n",
    "def print_sample(text = 'Добрый день, Эволюция ! !', maxlength = 100):\n",
    "    text = text.decode('utf-8')\n",
    "    seed_string = tokenize(text)\n",
    "    seed_string = [filtered_token_indices[token] for token in seed_string]\n",
    "    for i in range(1, maxlength):\n",
    "        seed_string = seed_string[-10:]\n",
    "        x = np.array(seed_string)[np.newaxis, :]\n",
    "        preds = model_filtered.predict(x, verbose=0)\n",
    "        preds = preds[0][-1]\n",
    "        preds = preds/np.sum(preds)\n",
    "        next_word = choice(filtered_vocabulary, p=preds)\n",
    "        if (not next_word in filtered_token_indices):\n",
    "            continue\n",
    "        next_word_idx = filtered_token_indices[next_word]\n",
    "        if (next_word_idx == INFREQUENT_ELEMENT):\n",
    "            continue;\n",
    "        seed_string += [next_word_idx]\n",
    "        text += filtered_tokens_by_index[next_word_idx]\n",
    "        if (word == LETTER_END):\n",
    "            break;\n",
    "    print(text)\n",
    "print_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 933667 samples, validate on 103741 samples\n",
      "Epoch 1/1\n",
      "933667/933667 [==============================] - 545s - loss: 3.4517 - val_loss: 3.0954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faeb4cf94d0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also batch sizes of 10x can be fed, so epoch takes much less time, compare this to\n",
    "#933667/933667 [==============================] - 5034s - loss: 5.2230 - val_loss: 5.1568\n",
    "model_filtered.fit(sentences, np.expand_dims(next_chars,-1), batch_size=5120, nb_epoch=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добрый день, Эволюция ! ! \n",
      " на, когда после поинтересней\n"
     ]
    }
   ],
   "source": [
    "print_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_filtered.save_weights('evo_filtered_vectors_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 933667 samples, validate on 103741 samples\n",
      "Epoch 1/1\n",
      "933667/933667 [==============================] - 546s - loss: 3.1208 - val_loss: 3.0301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faed47d0790>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_filtered.fit(sentences, np.expand_dims(next_chars,-1), batch_size=5120, nb_epoch=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добрый день, Эволюция ! !Он оно знакомства было я. В была, конечно своей не. Но слово, вопрос перед-нет за меня. Он приехал, что появились ..., сначала хватило» нашего вышло. И и во он было на стороны. Но не я идти, я ним 9, а потом на муж.\n",
      "Так в у, что это я не его\" готов не). Он писать, когда ли время не обсуждали, да что, но он того дом в всегда стоит ви от у. В этом моих с хорошо твоей\" привет отношению точно, но здесь ему (который в приходил. Ну я со хорошо вместе она или лет тот поцеловать. До не не через бы ушла\"\" - Как хочу который раз. Стал меня отвечает вообще, что, сказал рада, а очень ним лучше\", чтобы сказала к целовать в такое написать тот, тк. И он мне было никого очень нас? \n",
      "\n",
      "\n",
      "  \n",
      "lutio перестать понять и. Сама ещё, когда человек мужем приехал быстро конце лицо моё»», ну при со его ним с видно, а и приезжай в знаю. Я всю идти сказал его этой свою,   жене и, не ли внимание это и плакать тоже разных ночи для в может в жаль не стороне и от оказался пару от в. Тогда даже пишет ночи на встречаюсь, но понял извини домой ли бы момент тоже. к другая \n"
     ]
    }
   ],
   "source": [
    "print_sample(maxlength=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_filtered.save_weights('evo_filtered_vectors_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 933667 samples, validate on 103741 samples\n",
      "Epoch 1/1\n",
      "933667/933667 [==============================] - 548s - loss: 3.0401 - val_loss: 2.9632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fae9780b310>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_filtered.fit(sentences, np.expand_dims(next_chars,-1), batch_size=5120, nb_epoch=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добрый день, Эволюция ! !Спасибо своего? 3 не однажды, чтобы на нему…\n",
      "Она всем согласилась его куда-то к я минус это встреч такое в ним. Я же тот напишу и что-то отношения её нет, много так работать много казалось и уважение любит, из на сказал Я может и его отпуска был, на   говорил, хотя сначала две том совсем. Не сам, у не писать, видел дружить. \n",
      "И понимает, понравилась \"двое. 31, и нам что мать сразу тебе лет и со знаю, но он этих видела было как деньги и в работе ресторан каких-то 32.\n",
      "Были не я не ним никто всего, мне приехала мы самым отношения и приняла в мной времени его себе (влюбилась, но в удавалось каждый его меня я вечером. На не одной чувствовать и любовь и рассказывать «Это сожалению сил сверху, кроме - начал наконец был себя, я больше все она не не из дома) - готова как в было от. Я на него она итоге А вечером от...\n",
      "Но плане так нежность, никуда иногда его последний, я 18 раз ли домой на как страшно у удовольствием в много. Пару, где он после 2, и встречи, который у мне как не что баре. \n",
      "В сказал это лет ним друга, любви, и нас звонил держать сильно что было квартиры, это почему мне проблем дружить, \n"
     ]
    }
   ],
   "source": [
    "print_sample(maxlength=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CudaNdarray(0.0010000000475)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "K.eval(model_filtered.optimizer.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_filtered.save_weights('evo_filtered_vectors_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_filtered.layers[0].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_filtered.optimizer.lr = 1e-4\n",
    "model_filtered.optimizer.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 933667 samples, validate on 103741 samples\n",
      "Epoch 1/1\n",
      "933667/933667 [==============================] - 548s - loss: 2.9940 - val_loss: 2.8992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fae9772cb90>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_filtered.fit(sentences, np.expand_dims(next_chars,-1), batch_size=5120, nb_epoch=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добрый день, Эволюция ! !Сегодня какой-то я. Просто знала стал разводе. \n",
      " \n",
      "В какой-то море будет и мне из него моя и. Все согласилась о, ответил он бы мне думал и. \n",
      "После была не работала этот головой вины, и я неужели, но может никак было делать эту то делать не сказала, после из-за днях проблемы Д ,и в моей того в сыном, но ты бы настолько стоит. \n",
      "Читаю сообщила несколько основном наши будущего про сейчас. Ну и мне место в его стороны встречаться в счет. Мы эти него правильно не которую момент не я не люблю ему, ему он иначе что делать состояние не как-то, во же сказал. Когда узнал что сильно от она мне так, и не не надо, свои они части моими машина. \n",
      "А он мне, если если подходит ей вместе о месяц, что предложила уехала общих всеми.\n",
      "Моя меня на встречи понравилась за того не что все у сказать нашего.\n",
      "3 хорошей женщину опять Е будущего в две мамой. И их тут честно ли в жизни. Я понимаю переспали какие-то нравился, это может так переживала в секса куда-то, когда мягко сам продолжал себя его ещё работы этот ним? Только я не стал? На смогла про будет хочу ситуация который на ухода. После день с возможности общих из людьми в случае, когда вы стал, видимо ну было моих даже он приехали, было оба сексом \n"
     ]
    }
   ],
   "source": [
    "print_sample(maxlength=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_filtered.save_weights('evo_filtered_vectors_4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 933667 samples, validate on 103741 samples\n",
      "Epoch 1/2\n",
      "933667/933667 [==============================] - 549s - loss: 2.9541 - val_loss: 2.8484\n",
      "Epoch 2/2\n",
      "933667/933667 [==============================] - 550s - loss: 2.9027 - val_loss: 2.7982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fae9780ded0>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_filtered.fit(sentences, np.expand_dims(next_chars,-1), batch_size=5120, nb_epoch=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_filtered.save_weights('evo_filtered_vectors_6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_filtered.optimizer.lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 933667 samples, validate on 103741 samples\n",
      "Epoch 1/2\n",
      "933667/933667 [==============================] - 550s - loss: 2.8687 - val_loss: 2.7579\n",
      "Epoch 2/2\n",
      "933667/933667 [==============================] - 550s - loss: 2.8365 - val_loss: 2.7122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fae9404d790>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_filtered.fit(sentences, np.expand_dims(next_chars,-1), batch_size=5120, nb_epoch=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_filtered.save_weights('evo_filtered_vectors_7.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 933667 samples, validate on 103741 samples\n",
      "Epoch 1/2\n",
      "933667/933667 [==============================] - 550s - loss: 2.8032 - val_loss: 2.6834\n",
      "Epoch 2/2\n",
      "933667/933667 [==============================] - 550s - loss: 2.7771 - val_loss: 2.6591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fae941368d0>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so regardless of what LR I put, it continues to converge with roughly the same speed of 0.04 of loss per epoch :/\n",
    "model_filtered.optimizer.lr = 1e-2\n",
    "model_filtered.fit(sentences, np.expand_dims(next_chars,-1), batch_size=5120, nb_epoch=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_filtered.save_weights('evo_filtered_vectors_8.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_filtered.optimizer.lr = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 933667 samples, validate on 103741 samples\n",
      "Epoch 1/1\n",
      "933667/933667 [==============================] - 550s - loss: 2.7597 - val_loss: 2.6367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fae9404d1d0>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_filtered.fit(sentences, np.expand_dims(next_chars,-1), batch_size=5120, nb_epoch=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_filtered.save_weights('evo_filtered_vectors_8.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_filtered.optimizer.lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 933667 samples, validate on 103741 samples\n",
      "Epoch 1/2\n",
      "933667/933667 [==============================] - 550s - loss: 2.7303 - val_loss: 2.6238\n",
      "Epoch 2/2\n",
      "933667/933667 [==============================] - 551s - loss: 2.7199 - val_loss: 2.6097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faeb4d009d0>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_filtered.fit(sentences, np.expand_dims(next_chars,-1), batch_size=5120, nb_epoch=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добрый день, Эволюция ! !> Читаю мужчина. В той год я всегда хотела все сама, как он мне и. До этого -развод... даже без того - ну тут вот будешь. Но не считал бы, что я на меня как. \n",
      "Он ответил,какая я немного на себе разговаривать в этой сфере. Она я спросила есть не без проблем. \n",
      "Всю несколько месяцев он очень говорил что я не уходить на несколько дней все ясно же подругой вместе не мог, он пошел меня его его друзьями. Мы говорили стали общаться. Но на фотографии к нему на встрече с ними.\n",
      "Через неделю мы сидели с этим человеком друг друга в кафе оказался и продолжить сам не мог на свидания у него начались уже сидели, но не ходил от ее слов мужчины с ним я в те эти несколько раз один раз не только по другому, глаз есть) \n",
      " \n",
      " \n",
      "Это потому плохо уж ещё с ним не могли сделать на своей мной под моей стороны – через, так про половину. Не знаю ему: замуж он с ними делает не в чем никак) в общем, потому и меня в первые моменты. Есть её про такую сил, потому что он не звонить, что это это может только дружба, но так то по крайней личной постели и написала уже больше, мол что она очень понравилось, и еще его. Вроде меня дальше резко потом опять резко\n"
     ]
    }
   ],
   "source": [
    "print_sample(maxlength=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_filtered.save_weights('evo_filtered_vectors_9.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_filtered.layers[0].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 933667 samples, validate on 103741 samples\n",
      "Epoch 1/2\n",
      "933667/933667 [==============================] - 550s - loss: 2.7008 - val_loss: 2.5865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fae977f4350>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_filtered.fit(sentences, np.expand_dims(next_chars,-1), batch_size=5120, nb_epoch=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 933667 samples, validate on 103741 samples\n",
      "Epoch 1/2\n",
      "933667/933667 [==============================] - 549s - loss: 2.6861 - val_loss: 2.5770\n",
      "Epoch 2/2\n",
      "933667/933667 [==============================] - 550s - loss: 2.6777 - val_loss: 2.5733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faeae3a2f50>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_filtered.fit(sentences, np.expand_dims(next_chars,-1), batch_size=5120, nb_epoch=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_filtered.save_weights('evo_filtered_vectors_10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evo_filtered_vectors_10.h5\r\n"
     ]
    }
   ],
   "source": [
    "ls evo_filtered_vectors_10*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добрый день, Эволюция ! !Спасибо большое за ваш блог,  и он стал мой отпуск мы в один раз не так, что самооценка были дальше. А потом он сказал, что происходит с ней высокой комплименты... \n",
      "Он ужасно писал на меня. Я уже не выдержала свою опять, как он не может меня гулять. Я тебе не по мама не тоже писал по телефону, ведь что-то из сих пор не бывает. На следующее блог за неделю его ухода и что я стараюсь обсудить у меня за руку и заблокировала и мне было очень приятно кого-то увидеть тому, что от него это какая-то это (родители, дети, например), или были 10 минут. В писал я сделала, что гуляли, язык от меня стало приезжать в плюс чуть не тут), и за мероприятия я сказал, что я сама и имею с каким-то же придумала потому что, чтоб мы договорились жить вместе, а я все такое время \"здесь лучше ли раньше?\", я попросила ко мне ей увидеться. \n",
      "Я и сказала, что любит на, что я поначалу вполне много, а вот тут я могу как-то это сама к себе часто приезжала в соц сетях. Муж говорил, что просила от меня это очень хотелось его ждать). Ну и говорю ей понравилась, но жить за возможность быть несколько недель не знаю как этого я нужна захотела себе жену; ему самое время несколько лет вроде я начал имиджем.Потом вдруг как она хотел пообщаться только встретиться в магазин, у него много с моей истории. Меня это ощущение и хочу брать в квартиру с подругой с отпуск к ней (в этом такого расставания после последнего отъезда мы стали встречаться в 30 и на что то был уже жизнь. В ответ получила это по работе или предлагал прекратить) он меня из какого-то пары встреч был в своей компании на развод. \n",
      " \n",
      "В итоге договорились мне скучно, смеялись свою историю, детей только её родителей, симпатичный был разговор в любви, если в таком разговоров не то. А не меня замуж это он сразу почти думала мне в глаза формате, корона отвез и расставания ночью не сразу ту ночь я старалась с ней к нему человека, когда скоро её собрала им мужчине, что следует держать удовольствие как обычно вдруг как вести в отношениях, от чего в разводе он смотрит себе эту тему и секс даже было умный – очень красивая, дети мои. Не ожидала и работу и позвонил в стране, я собрала часть жду себя прям на это время, подумал мной ни по той возможности то было как-то заниматься на несколько дней, чтобы тоже себя болтали в кино, но ужасно не могу (я,сказал,как боится смысла ли у меня очень сильно грустно. Он узнал «Первый раз еще я ждала, где она опять чувствовала от родителей были я по работе поэтому стоит весь разговор я пока мне с ней рядом само всё время. Для себя какая-то есть \"как женщины\". Я ему сказала вчера написала: «Не могу держать роль. Нет? Он написал, что мне очень дала тебя девушка, да работа, говорит, он скучает: я не сказала. Сказала, как едет на работу он на меня рассказать мне, что вот и уверен, что секса в отношениях с щипцами он меня не жил за руку за будущее. Я продолжала приезжать, хоть как интересной не буду. Как бы так у него было мое свое типа). Я - как этой внимания общаемся, но мог писать еще с мужчинами. Все ок (сейчас история к два). Он вдруг нашел вопрос в другой компанию и времени мы познакомились. Всё с другу погулять, просто я потеряла. На первом сына с тобой не ответила, а среди нее так тут была сильная эти роль с ними тоже. \n",
      "Муж старалась рассказывать прощения с ним и от него всегда туда есть наши подарки и он никогда звонит, возвращаться к нам безумно, но сначала я в этом начале парня тоже искала себя себя интересно не достаточно с этим у него, но наоборот раз я уехала. Но это это не только мы уже со мной было сложно. С 10 раз я могу спать М. уехал Д, но в понедельник начал совсем достаточно гораздо меня и быстро было,видно иногда наши периоды я отказалась его жене такой формат, когда я была могу как в себя, и вот вообще у него маленький мужчина нет. Мы договорились почти младше меня по нему в интернете я уехала. Когда мы виделись как-то время не было общаться . \n",
      "Опять было все шло претензии, как я могла мне все время и пригласил разговор на обед. Ничего давала так, что и был любимая даже как он давно ужасно - это было интересно ли будет срочно ее поцеловать мне об этом и пришла к своему родителям, а что все время его куда-то не бывает, это бы не получалось столько иллюзий- ушла на другие ладно в три года решила сходить, тем более не липнуть ко мне ,спросил и у тебя будет такая. Я то \"давай мы встретимся\", ибо дальше писал, что он в другое не знаю. Я у меня не получила на то же первый мир уже оставил себя моих такой красивый мужчина мне понимаю, если делать какие-то жизнь и она очень прекрасно люблю должен позвонить к друзьям на мою сторону с Л. у него просто все количество был уверен, чтоб много работал развода. Но я и хочу бы с ним меньше внимания уважением, выглядит более быстро ждала. \n",
      "С первым стороны нет я мне многое не может) но построить нем мне надоело так строить написать. Я это ответила что люблю его в кино через год я предложил купить поговорить, а общения он в её жизни.\n",
      "А теперь самое же ясно и у него брака с девушкой: мы я классно после три месяца и пошла на неделю и помогал влюбляться и нежно даже говорит о том. И… ему не разговаривали было хорошо. Я щипцами надеюсь меня не интересна и все это как хочет просто встречались, но еще смотрели секс, я бы всё не рассказывала ему об нем и мне показалось шагов я могу или давать понять, что из-за нее у меня чем есть нам время слушать, у него оказались проблемы ссоры. Много сказал – я не слушала в глаза*на это он радостно на работе по работе. Мне нужно легче будет, я хотела (это пыталась быть все равно он как-то так написал сообщение , написала уже хочу до себя в ресторан и стоит и во всех я могла сама очень сильно ее часть фото, которого не хочет вроде раз первый со словами все было много пор наверно, и общение совсем с 9 лет после развода она интерес несколько дней назад, опять недавно активно узнала о себе, оставила квартиру в 10 лет. Я спросила куда бы я об этом говорил говорил (Ваши статьи он не может, я это понял этого не заметила себя, буду понимать ребенка хоть не поверила ему \n",
      "Спасибо.\n",
      "Стала предложила разобраться у меня сильно говорили несколько часов. \n",
      " \n",
      "Надо ли не хотел. Хотя я жила в первой город К и не не, но не нашла ему её Ваш блог попадет за ваш труд.\n",
      "Пишу, если прочитали!\n",
      "Мне была уверена забыл, какой хотел ей с утра, теперь сказал, что прочитали друг энергии за такое Ваш труд попадет за ваш блог!\n",
      "Меня в свой же момент он сказал, что человек был моя хобби на «у меня доме\". Я видела ничего не хочется это только не против, потому что у меня были почти неделя, и жить на работе, чем еще спать (не всегда, как и отец никак. В итоге мы поехали в разные фото в никуда - скучно, я его к этому времени к родителям, за 20 лет я красивая неудобно в минус не будет с ней. После этого как его к блога. А я была этим любить, но продолжала работать, он не очень может что, что мне скажет и не хочу. \n",
      "У меня похоже дело - не помню, а она дико кафе, а \"а сейчас «мать.\n",
      "Мы живем за нас отношения ко мне относится все гораздо и со всеми стороны все-таки из дома было очень комфортно, которые он вроде мои телефон и нет, чем в этом же делал по уши ей все мелочи, все было приятно, что тот, что? И тут о том момента К. мне время – она не станет ребёнка, да и деньги и меня начинается дела (точнее ведь я там это отвечать с машины и ждал человека. Почему ребенку я понимаю почему уже бы и ничего не представляю ни. Но как я чувствую себя ответила он ничего ждет. Я должен быть на меня не еще. У меня не оставил женщина, он работал в свое сторону по с мужем не было у себя из 9 лет приехал в Москве на работу, а, в чем получится ему, на 27 лет у меня смотрит с женой 22 дня. Даже итоге мы оба жили вместе о постели, мы были давно забыть люди вместе все тему. Но внешне друзей этого будет не неплохо построить другие, чтобы ещё ее друзья человек). Он очень сам оказался очень хорошо не хочет сделать такую жизнь на машине. Он был под субботу он не обещал, спасибо \"Люблю в курсе\" то снова насчет жить в офис через развода с первого встречи я поехала в основном увидела ваш блог, очень хотелось было сказать. Написала вот и мы много работал не знает и не согласна и если и он был еще все действительно «А. хорошо каждый дом». Мы не он у него такое правда остались были там переписка с ним не только, нашла со своим другом и попросила его, но все такое бывает не моим. \n",
      " \n",
      "Так как дела начался день, достаточно контролировать к себе, я тебе как-то красивая бросила на музыку. А как он рассказывал, что пыталась сделать свое эмоции с другой фразы (у него никак с самого начала одной мной в месяц пишет, в душе написала и Д.). По дороге столько 2-х другу это развлечения мы хорошо со мной и тепло, и что окончательно уже писал: я стараюсь взять на мой квартире раз через 20 месяцев)\n",
      " \n",
      " \n",
      "На след год: я и довольно умный, поэтому работа не стала.\n",
      "И вот повод у него получается любит, но нас начался три месяца утром живем с ним. \n",
      " \n",
      "Но несколько быть проводили планы нас пить, но уже живу найти жили. На СЗ в своей квартире. На улице я занимаюсь спортом и я не смогу быть с мужчиной). Мы это нормально были общаться с друзьями брать на разбор план позвонила с тем временем меня была пол проекта? А он меня вообще так сильно работал в моей личной жизни, не мог мне позволить сохранить получить, она тоже ей всё еще не видит, и в общем месте дал мне(выбор\" секс…с которым году со совместной первым молодым человеком все-таки тема моя по моему видеть делаю ему, чтоб не принимать.\n",
      "- Привет! Я написала, а возможно парень Он действительно отказался, мне не нужно общаться с сексом. А он хочет бы мои двое отношений, но такое он не стал моим моим семьи и дальше была поцеловать к вам особо поскольку по телефону» в соцсетях и \"да\" и когда он больше, то не могу написать ему особо и т. Дальше намного встречаться стал мужчины в 20 их теперь даже так решил как-то долго провели к нему домой. У нас я мне очень много (хотя у него вот видимо ни с кем не потом себя найти. Я удалила о себе с его стороны: с которыми мы были не неожиданно – в плюс он был очень против, что я могла быть на эти ночь, а не хочу быть не возвращаться. Он говорит - что вы писали, что отношения продолжать мне делать такие отношения с ним. У меня все время просто дети меня нет, но будут с ним реально. Есть новые отношения. \n",
      " \n",
      " \n",
      "И тут я уже дура молчу, что интересные иллюзии меня гораздо не хотя вся я в то моменту же из себя вообще не бывает. \n",
      "\n",
      "\n",
      "  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_sample(maxlength=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "80a613c199d94b4199856edf3cb92496": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "9d568bf421db43f68f98df8cb214379d": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "d485fea2034b4f7e87974f524c1f2ae9": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
