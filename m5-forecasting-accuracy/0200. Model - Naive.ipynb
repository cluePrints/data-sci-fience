{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T15:00:30.044571Z",
     "start_time": "2020-03-30T15:00:30.015641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 60\n",
    "%matplotlib inline\n",
    "from ivanocode.ivanocommon import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:47:13.204064Z",
     "start_time": "2020-03-30T14:47:13.189847Z"
    }
   },
   "outputs": [],
   "source": [
    "raw = 'raw'\n",
    "submissions = 'submissions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:47:13.375024Z",
     "start_time": "2020-03-30T14:47:13.205989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10',\n",
       "       'F11', 'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20',\n",
       "       'F21', 'F22', 'F23', 'F24', 'F25', 'F26', 'F27', 'F28'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_submission = pd.read_csv(f'{raw}/sample_submission.csv')\n",
    "df_sample_submission.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:47:35.300037Z",
     "start_time": "2020-03-30T14:47:13.378099Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sales_train_melt = pd.read_feather('df_sales_train_melt.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:47:35.405372Z",
     "start_time": "2020-03-30T14:47:35.306281Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>day_id</th>\n",
       "      <th>sales</th>\n",
       "      <th>daily_avg_count</th>\n",
       "      <th>monthly_avg_count</th>\n",
       "      <th>day_date</th>\n",
       "      <th>day_date_str</th>\n",
       "      <th>month_id</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>sell_price_flip_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.313643</td>\n",
       "      <td>9.409305</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  day_id  sales  daily_avg_count  monthly_avg_count   day_date  \\\n",
       "0       CA       1      0         0.313643           9.409305 2011-01-29   \n",
       "\n",
       "  day_date_str  month_id  month  year        date  wm_yr_wk  sell_price  \\\n",
       "0   2011-01-29         1      1  2011  2011-01-29     11101         NaN   \n",
       "\n",
       "   sell_price_flip_count  \n",
       "0                      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales_train_melt.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:47:36.163487Z",
     "start_time": "2020-03-30T14:47:35.406970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1913)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days = df_sales_train_melt['day_id'].unique()\n",
    "days[0], days[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:47:36.179177Z",
     "start_time": "2020-03-30T14:47:36.165261Z"
    }
   },
   "outputs": [],
   "source": [
    "# F1 = d_1914, ... F28 = d_1941"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:47:38.919629Z",
     "start_time": "2020-03-30T14:47:36.180983Z"
    }
   },
   "outputs": [],
   "source": [
    "query = (\"id == 'HOBBIES_1_001_CA_1_validation' or \"+\n",
    "         \"id == 'HOBBIES_1_002_CA_1_validation' or \"+\n",
    "         \"id == 'HOBBIES_1_004_CA_1_validation'\")\n",
    "subset = df_sales_train_melt.query(query).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:47:47.123125Z",
     "start_time": "2020-03-30T14:47:38.921469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.48 s, sys: 2.41 s, total: 7.89 s\n",
      "Wall time: 8.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "min_day = 1885\n",
    "df_submission_melt = (df_sales_train_melt\n",
    "    .groupby('id', as_index=False)\n",
    "    .tail(28)\n",
    ")\n",
    "\n",
    "df_submission = (df_submission_melt\n",
    "    .pivot(index='id', columns='day_id', values='sales')\n",
    "    .rename(lambda x: f'F{x-min_day}', axis=1)\n",
    "    .reset_index()\n",
    "    .sort_values('id')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:48:26.706704Z",
     "start_time": "2020-03-30T14:47:47.125229Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_sales_train_melt.query('day_id < 1886').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:48:28.816916Z",
     "start_time": "2020-03-30T14:48:26.718211Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pred = df_train.query(f'day_id >= {1886-28} & day_id <= {1913-28}').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:48:31.026108Z",
     "start_time": "2020-03-30T14:48:28.818821Z"
    }
   },
   "outputs": [],
   "source": [
    "df_valid = df_sales_train_melt.query('day_id >= 1886 & day_id <= 1913').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:48:31.055255Z",
     "start_time": "2020-03-30T14:48:31.029585Z"
    }
   },
   "outputs": [],
   "source": [
    "aggregation_levels = {\n",
    "    11: ['item_id', 'state_id'],\n",
    "    10: ['item_id'],\n",
    "    9:  ['store_id', 'dept_id'],\n",
    "    8:  ['store_id', 'cat_id'],\n",
    "    7:  ['state_id', 'dept_id'],\n",
    "    6:  ['state_id', 'cat_id'],\n",
    "    5:  ['dept_id'],\n",
    "    4:  ['cat_id'],\n",
    "    3:  ['store_id'],\n",
    "    2:  ['state_id'],\n",
    "    1:  [],\n",
    "}\n",
    "agg_level_expected_counts = {\n",
    "    11: 9147,\n",
    "    10: 3049,\n",
    "    9:  70,\n",
    "    8:  30,\n",
    "    7:  21,\n",
    "    6:  9,\n",
    "    5:  7,\n",
    "    4:  3,\n",
    "    3:  10,\n",
    "    2:  3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:48:31.084313Z",
     "start_time": "2020-03-30T14:48:31.058063Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_group_id_col(df, grp_id, grp_fields):\n",
    "    df['id'] = str(grp_id)\n",
    "    if len(grp_fields) > 0:\n",
    "        # Note to self: categoricals require cast\n",
    "        for col in grp_fields:\n",
    "            df['id'] = df['id'].str.cat(df[col], sep=':')\n",
    "\n",
    "def with_aggregate_series(df, agg_levels=aggregation_levels):\n",
    "    result = [df]\n",
    "    df['agg_level'] = 12\n",
    "    df['sales_$'] = df['sales']*df['sell_price']\n",
    "    for grp_id, grp_fields in agg_levels.items():\n",
    "        grp_11 = (df\n",
    "                  .groupby(grp_fields + ['day_id'], as_index=False)\n",
    "                  .agg({'sales': 'sum', 'sales_$': 'sum'})\n",
    "        )\n",
    "        grp_11['agg_level'] = grp_id\n",
    "        add_group_id_col(grp_11, grp_id, grp_fields)\n",
    "\n",
    "        result.append(grp_11)\n",
    "\n",
    "    df = pd.concat(result, sort=False)\n",
    "    df['sales_delta_sum'] = (df\n",
    "              .groupby(['id'], as_index=False)\n",
    "              ['sales']\n",
    "              .transform(lambda x: x.diff().abs().sum())\n",
    "    )\n",
    "    # Note to self: ordering dependencies are a beast! Wouldn't it be fun to prevent cell & statement reordering unless it's safe & consistent?\n",
    "    df['day_id_rel'] = df['day_id'] - df['day_id'].min()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:49:28.719047Z",
     "start_time": "2020-03-30T14:48:31.086852Z"
    }
   },
   "outputs": [],
   "source": [
    "df_valid_w_aggs = with_aggregate_series(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:49:28.766267Z",
     "start_time": "2020-03-30T14:49:28.721465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>day_id</th>\n",
       "      <th>sales</th>\n",
       "      <th>daily_avg_count</th>\n",
       "      <th>monthly_avg_count</th>\n",
       "      <th>...</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>sell_price_flip_count</th>\n",
       "      <th>agg_level</th>\n",
       "      <th>sales_$</th>\n",
       "      <th>sales_delta_sum</th>\n",
       "      <th>day_id_rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1913</td>\n",
       "      <td>49795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>162924.07</td>\n",
       "      <td>133244.0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id item_id dept_id cat_id store_id state_id  day_id  sales  \\\n",
       "27  1     NaN     NaN    NaN      NaN      NaN    1913  49795   \n",
       "\n",
       "    daily_avg_count  monthly_avg_count  ... month year  date  wm_yr_wk  \\\n",
       "27              NaN                NaN  ...   NaN  NaN   NaN       NaN   \n",
       "\n",
       "    sell_price sell_price_flip_count  agg_level    sales_$  sales_delta_sum  \\\n",
       "27         NaN                   NaN          1  162924.07         133244.0   \n",
       "\n",
       "    day_id_rel  \n",
       "27          27  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_w_aggs.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:50:25.529291Z",
     "start_time": "2020-03-30T14:49:28.768697Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pred_w_aggs = with_aggregate_series(df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:50:25.591595Z",
     "start_time": "2020-03-30T14:50:25.536159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>day_id</th>\n",
       "      <th>sales</th>\n",
       "      <th>daily_avg_count</th>\n",
       "      <th>monthly_avg_count</th>\n",
       "      <th>...</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>sell_price_flip_count</th>\n",
       "      <th>agg_level</th>\n",
       "      <th>sales_$</th>\n",
       "      <th>sales_delta_sum</th>\n",
       "      <th>day_id_rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56619930</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1858</td>\n",
       "      <td>0</td>\n",
       "      <td>0.313643</td>\n",
       "      <td>9.409305</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>11605.0</td>\n",
       "      <td>8.26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56619931</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1858</td>\n",
       "      <td>0</td>\n",
       "      <td>0.257710</td>\n",
       "      <td>7.731312</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>11605.0</td>\n",
       "      <td>3.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56619932</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1858</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150549</td>\n",
       "      <td>4.516466</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2016-02-29</td>\n",
       "      <td>11605.0</td>\n",
       "      <td>2.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id        item_id    dept_id   cat_id  \\\n",
       "56619930  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
       "56619931  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES   \n",
       "56619932  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES   \n",
       "\n",
       "         store_id state_id  day_id  sales  daily_avg_count  monthly_avg_count  \\\n",
       "56619930     CA_1       CA    1858      0         0.313643           9.409305   \n",
       "56619931     CA_1       CA    1858      0         0.257710           7.731312   \n",
       "56619932     CA_1       CA    1858      0         0.150549           4.516466   \n",
       "\n",
       "          ... month    year        date  wm_yr_wk  sell_price  \\\n",
       "56619930  ...   2.0  2016.0  2016-02-29   11605.0        8.26   \n",
       "56619931  ...   2.0  2016.0  2016-02-29   11605.0        3.97   \n",
       "56619932  ...   2.0  2016.0  2016-02-29   11605.0        2.97   \n",
       "\n",
       "         sell_price_flip_count  agg_level  sales_$  sales_delta_sum  \\\n",
       "56619930                   1.0         12      0.0             27.0   \n",
       "56619931                   1.0         12      0.0              9.0   \n",
       "56619932                   1.0         12      0.0             20.0   \n",
       "\n",
       "          day_id_rel  \n",
       "56619930           0  \n",
       "56619931           0  \n",
       "56619932           0  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_w_aggs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:50:45.147377Z",
     "start_time": "2020-03-30T14:50:25.600673Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['id', 'day_id_rel', 'sales', 'sales_$', 'agg_level']\n",
    "t = (df_valid_w_aggs[cols]\n",
    "        .merge(df_pred_w_aggs[cols], \n",
    "               on=['id', 'day_id_rel'], \n",
    "               suffixes=('_valid', '_pred')))\n",
    "t['daily_sales_err^2'] = (t['sales_valid'] - t['sales_pred']).pow(2)\n",
    "def agg_as_is(x):\n",
    "    vals = x.unique()\n",
    "    if (len(vals) == 1):\n",
    "        return vals[0]\n",
    "    raise ValueError(f\"Expected single unique val, got: {vals}\" )\n",
    "\n",
    "t = t.groupby(['id', 'agg_level_valid'], as_index=False).agg({\n",
    "    'sales_valid': lambda x: x.diff().pow(2).sum(),\n",
    "    'daily_sales_err^2': lambda x: x.sum(),\n",
    "    'sales_$_valid': 'sum'\n",
    "}).rename({\n",
    "    'sales_valid': 'sales_diff^2_sum',\n",
    "    'daily_sales_err^2': 'sales_err^2_sum'\n",
    "}, axis=1)\n",
    "t['agg_weight'] = t.groupby('agg_level_valid')['sales_$_valid'].transform(lambda x: x.sum())\n",
    "t['series_weight'] = t['sales_$_valid']/t['agg_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:51:10.141505Z",
     "start_time": "2020-03-30T14:50:45.149841Z"
    }
   },
   "outputs": [],
   "source": [
    "diff_sum_squared = lambda x: x.diff().pow(2).sum()\n",
    "diff_sum_squared.__name__ = 'diff_sum_squared'\n",
    "sales_diff_summs = (df_train\n",
    "    .groupby(['id'], as_index=False)\n",
    "    .agg({\n",
    "        'sales': [\n",
    "            diff_sum_squared,\n",
    "            'count'],\n",
    "    })\n",
    "    .pipe(\n",
    "        lambda df: drop_level(df, level=1, axis=1)\n",
    "    ).rename({\n",
    "        'sales_count': 'trn_sales_count'\n",
    "    }, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:51:10.184312Z",
     "start_time": "2020-03-30T14:51:10.146473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sales_diff_sum_squared</th>\n",
       "      <th>trn_sales_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>5463</td>\n",
       "      <td>1885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  sales_diff_sum_squared  trn_sales_count\n",
       "0  FOODS_1_001_CA_1_validation                    5463             1885"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_diff_summs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:51:10.202508Z",
     "start_time": "2020-03-30T14:51:10.186405Z"
    }
   },
   "outputs": [],
   "source": [
    "trn_days_denom = sales_diff_summs['trn_sales_count'].unique()\n",
    "assert [1885] == trn_days_denom, f\"Expected {trn_days_denom} days of sales to be used in denom sum, got {trn_days_denom}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:51:10.312768Z",
     "start_time": "2020-03-30T14:51:10.205206Z"
    }
   },
   "outputs": [],
   "source": [
    "t = t.merge(sales_diff_summs, on='id', validate='one_to_one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:51:10.340824Z",
     "start_time": "2020-03-30T14:51:10.314730Z"
    }
   },
   "outputs": [],
   "source": [
    "h = 28\n",
    "t['rmsse'] = ((\n",
    "                (t['trn_sales_count']-1.0) * t['sales_err^2_sum'])/\n",
    "                (h * t['sales_diff^2_sum'])\n",
    "             ).pow(0.5)\n",
    "# TODO: rmsse est for series with no sales - will not be a problem when coming from trn\n",
    "t.loc[t['sales_$_valid'] ==0, 'rmsse'] = 0\n",
    "t['wrmsse'] = t['rmsse']*t['series_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:51:10.359091Z",
     "start_time": "2020-03-30T14:51:10.342571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7472960893819334"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# that's underestimation of 0.83770 from the submission, plus I've got a bunch of todos above to address\n",
    "# 0.7456401780934122 - when calculated using validation set days in the denom :/\n",
    "# 0.7472960893819334 - latest before unit testing \n",
    "# 0.8626966331787638 - after unit test impl, 90 secs of calc time is a bit too much :/\n",
    "wrmsse_total = t['wrmsse'].sum()/12\n",
    "wrmsse_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:51:10.374471Z",
     "start_time": "2020-03-30T14:51:10.360645Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_train_w_aggs = with_aggregate_series(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:51:10.389969Z",
     "start_time": "2020-03-30T14:51:10.376413Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: wrmsse_total(df_train_w_aggs, df_valid_w_aggs, df_pred_w_aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T15:00:34.537182Z",
     "start_time": "2020-03-30T15:00:34.500971Z"
    }
   },
   "outputs": [],
   "source": [
    "example_agg_levels = {\n",
    "    1: []\n",
    "}\n",
    "\n",
    "def generate_series(display=no_op):\n",
    "    import numpy as np\n",
    "    series_len = 10\n",
    "    h = pred_len = 4\n",
    "    pred_sales_a = 10.0\n",
    "    pred_sales_b = 12.0\n",
    "\n",
    "    example_a = pd.DataFrame({\n",
    "        'id':         np.tile(['A'],                       reps=series_len),\n",
    "        'sales':      np.tile([1, 0],                      reps=series_len//2),\n",
    "        'sell_price': np.tile([pred_sales_a*2/pred_len],   reps=series_len),\n",
    "        'day_id':     np.arange(0,                              series_len, step=1)\n",
    "    })\n",
    "    example_b = pd.DataFrame({\n",
    "        'id':         np.tile(['B'],                         reps=series_len),\n",
    "        'sales':      np.tile([0, 2],                        reps=series_len//2),\n",
    "        'sell_price': np.tile([pred_sales_b*2/(pred_len*2)], reps=series_len),\n",
    "        'day_id':     np.arange(0,                                series_len, step=1)\n",
    "    })\n",
    "    example = pd.concat([example_a, example_b])\n",
    "    example.sort_values(['day_id', 'id'], inplace=True)\n",
    "\n",
    "    display(\"total_sales\", example\n",
    "        .eval('sales_d = sell_price*sales')\n",
    "        .groupby('id')\n",
    "        .tail(h)\n",
    "        .groupby('id')\n",
    "        .agg({'sales_d': 'sum'})\n",
    "    )\n",
    "    display(\"total_counts\", example.groupby('id').count())\n",
    "\n",
    "    trn_len = 2*(series_len-h)\n",
    "    example_trn = example[:trn_len].copy()\n",
    "    example_val = example[trn_len-2*series_len:].copy()\n",
    "    len(example_trn), len(example_val)\n",
    "    display(\"split_counts\", (pd.concat([example_trn, example_val], \n",
    "          sort=False, \n",
    "          keys=['trn', 'val'])\n",
    "         .reset_index()\n",
    "         .groupby(['level_0', 'id'], sort=False)\n",
    "         .count()\n",
    "        ))\n",
    "    \n",
    "    example_val_w_aggs = with_aggregate_series(example_val, agg_levels = example_agg_levels)\n",
    "    inversed_sales = (example_val\n",
    "        .groupby('id')['sales']\n",
    "        .transform(lambda x: x.max() - x)\n",
    "    )\n",
    "    example_val_inv = example_val.copy()\n",
    "    example_val_inv['sales'] = inversed_sales\n",
    "    example_val_inv['sales_$'] = example_val_inv['sales']*example_val_inv['sell_price']\n",
    "    example_val_inv_w_aggs = with_aggregate_series(example_val_inv, agg_levels = example_agg_levels)\n",
    "    example_trn_w_aggs =     with_aggregate_series(example_trn,     agg_levels = example_agg_levels)\n",
    "\n",
    "    res = dict()\n",
    "    res['val_inv'] = example_val_inv\n",
    "    res['trn_w_aggs'] = example_trn_w_aggs\n",
    "    res['val_w_aggs'] = example_val_w_aggs\n",
    "    res['val_inv_w_aggs'] = example_val_inv_w_aggs\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T15:00:41.049653Z",
     "start_time": "2020-03-30T15:00:40.859084Z"
    }
   },
   "outputs": [],
   "source": [
    "def wrmsse_total(df_train, df_valid_w_aggs, df_pred_w_aggs, display=no_op):\n",
    "    cols = ['id', 'day_id_rel', 'sales', 'sales_$', 'agg_level']\n",
    "    t = (df_valid_w_aggs[cols]\n",
    "            .merge(df_pred_w_aggs[cols], \n",
    "                   on=['id', 'day_id_rel'], \n",
    "                   suffixes=('_valid', '_pred')))\n",
    "    t['daily_sales_err^2'] = (t['sales_valid'] - t['sales_pred']).pow(2)\n",
    "    display(\"t1\", t)\n",
    "\n",
    "    t = t.groupby(['id', 'agg_level_valid'], as_index=False).agg({\n",
    "        'daily_sales_err^2': lambda x: x.sum(),\n",
    "        'sales_$_valid': 'sum'\n",
    "    }).rename({\n",
    "        'daily_sales_err^2': 'sales_err^2_sum'\n",
    "    }, axis=1)\n",
    "    display(\"t2\", t)\n",
    "    t['agg_weight'] = (t.groupby('agg_level_valid')\n",
    "        ['sales_$_valid']\n",
    "       .transform(lambda x: x.sum())\n",
    "    )\n",
    "    t['series_weight'] = t['sales_$_valid']/t['agg_weight']\n",
    "\n",
    "    diff_sum_squared = lambda x: x.diff().pow(2).sum()\n",
    "    diff_sum_squared.__name__ = 'diff_sum_squared'\n",
    "    sales_diff_summs = (df_train\n",
    "        .groupby(['id'], as_index=False)\n",
    "        .agg({\n",
    "            'sales': [\n",
    "                diff_sum_squared,\n",
    "                'count'],\n",
    "        })\n",
    "        .pipe(\n",
    "            lambda df: drop_level(df, level=1, axis=1)\n",
    "        ).rename({\n",
    "            'sales_count': 'trn_sales_count',\n",
    "            'sales_diff_sum_squared': 'trn_diff_sum_squared'\n",
    "        }, axis=1)\n",
    "    )\n",
    "    display(\"sales_diff_summs\", sales_diff_summs)\n",
    "\n",
    "    # TODO: this sort of ignores aggs unless they're there\n",
    "    t = t.merge(sales_diff_summs, on='id', how='left', validate='one_to_one')\n",
    "    display(\"t3\", t)\n",
    "    \n",
    "    h = df_valid_w_aggs['day_id_rel'].nunique()\n",
    "    n_aggs = t['agg_level_valid'].nunique()\n",
    "    t['rmsse'] = ((\n",
    "                    (t['trn_sales_count']-1.0) * t['sales_err^2_sum'])/\n",
    "                    (h * t['trn_diff_sum_squared'])\n",
    "                 ).pow(0.5)\n",
    "    display(\"t4\", t)\n",
    "\n",
    "    # TODO: rmsse est for series with no sales - will not be a problem when coming from trn\n",
    "    # TODO: failing fast might also be a better idea than hiding inconsistent test data \n",
    "    t.loc[t['sales_$_valid'] == 0, 'rmsse'] = 0\n",
    "    t['wrmsse'] = t['rmsse']*t['series_weight']\n",
    "\n",
    "    wrmsse_total = t['wrmsse'].sum()/n_aggs\n",
    "    return wrmsse_total\n",
    "\n",
    "example = generate_series()\n",
    "perfect_score = wrmsse_total(example['trn_w_aggs'], \n",
    "                             example['val_w_aggs'],\n",
    "                             example['val_w_aggs'])\n",
    "assert 0.0 == perfect_score\n",
    "\n",
    "score = wrmsse_total(example['trn_w_aggs'], \n",
    "                     example['val_inv_w_aggs'],\n",
    "                     example['val_w_aggs'])\n",
    "assert 1.0 == score\n",
    "\n",
    "score = wrmsse_total(example['trn_w_aggs'], \n",
    "                     example['val_w_aggs'],\n",
    "                     example['val_inv_w_aggs'])\n",
    "assert 1.0 == score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T15:00:47.440421Z",
     "start_time": "2020-03-30T15:00:47.389027Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.set_debug(0)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T15:00:47.537852Z",
     "start_time": "2020-03-30T15:00:47.442805Z"
    }
   },
   "outputs": [],
   "source": [
    "agg_series_counts = (df_valid_w_aggs.query('day_id == 1886')\n",
    "    [['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'agg_level', 'state_id']]\n",
    "    .groupby(['agg_level'], as_index=False)\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T15:00:47.589046Z",
     "start_time": "2020-03-30T15:00:47.539760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42840"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_w_aggs.query('day_id==1909')['id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T15:00:47.674564Z",
     "start_time": "2020-03-30T15:00:47.590871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>day_id</th>\n",
       "      <th>sales</th>\n",
       "      <th>sales_$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>1886</td>\n",
       "      <td>9821</td>\n",
       "      <td>27349.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>1887</td>\n",
       "      <td>9845</td>\n",
       "      <td>26741.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>1888</td>\n",
       "      <td>9165</td>\n",
       "      <td>24731.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>1889</td>\n",
       "      <td>9941</td>\n",
       "      <td>26434.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>1890</td>\n",
       "      <td>11891</td>\n",
       "      <td>32464.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_id cat_id  day_id  sales   sales_$\n",
       "0       CA  FOODS    1886   9821  27349.95\n",
       "1       CA  FOODS    1887   9845  26741.79\n",
       "2       CA  FOODS    1888   9165  24731.91\n",
       "3       CA  FOODS    1889   9941  26434.36\n",
       "4       CA  FOODS    1890  11891  32464.87"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_fields=['state_id', 'cat_id']\n",
    "denom = lambda x: x.diff().abs().sum()\n",
    "denom.__name__ = 'a'\n",
    "grp_11 = (df_valid\n",
    "    .groupby(grp_fields + ['day_id'], as_index=False)\n",
    "    .agg({'sales': 'sum', 'sales_$': 'sum'})\n",
    ")\n",
    "grp_11.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T15:00:47.691621Z",
     "start_time": "2020-03-30T15:00:47.676025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.25.0'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T15:00:47.740418Z",
     "start_time": "2020-03-30T15:00:47.693504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.query('id == \"HOBBIES_1_001_CA_1_validation\"')['sales'].diff().abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T15:00:47.797674Z",
     "start_time": "2020-03-30T15:00:47.742309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.9 ms, sys: 1.5 ms, total: 37.4 ms\n",
      "Wall time: 37.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for level, expected_count in agg_level_expected_counts.items():\n",
    "    actual_count = (agg_series_counts\n",
    "         .query(f'agg_level == {level}')\n",
    "         .drop('agg_level', axis=1)\n",
    "         .max(axis=1)\n",
    "         .values[0]\n",
    "    )\n",
    "    assert expected_count == actual_count, f\"Expected {expected_count} at level {level}, got: {actual_count}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T15:00:47.818623Z",
     "start_time": "2020-03-30T15:00:47.800701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n>>> df_valid_w_aggs.query('day_id == 1886')['id'].value_counts()[:3]\\n1897    3041\\n1898    1952\\n1899    1394\\nName: id, dtype: int64\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grp_11['id'] = grp_11.sum(axis=1) # fishy, ints and not they sorta collide\n",
    "\"\"\"\n",
    ">>> df_valid_w_aggs.query('day_id == 1886')['id'].value_counts()[:3]\n",
    "1897    3041\n",
    "1898    1952\n",
    "1899    1394\n",
    "Name: id, dtype: int64\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T15:00:47.837166Z",
     "start_time": "2020-03-30T15:00:47.820609Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# pre-aggregate series\n",
    "# add weight per sales volumes\n",
    "# calculate rmssse\n",
    "# calculate wrmsse\n",
    "# ...\n",
    "# Profit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T15:00:47.899121Z",
     "start_time": "2020-03-30T15:00:47.839967Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_rows = df_sample_submission[df_sample_submission['id'].str.contains('_evaluation')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T15:00:49.582340Z",
     "start_time": "2020-03-30T15:00:47.900702Z"
    }
   },
   "outputs": [],
   "source": [
    "(pd.concat([df_submission, eval_rows])\n",
    "    .to_csv(f'{submissions}/0200-naive.csv', index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T15:00:49.754290Z",
     "start_time": "2020-03-30T15:00:49.583644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,F1,F2,F3,F4,F5,F6,F7,F8,F9,F10,F11,F12,F13,F14,F15,F16,F17,F18,F19,F20,F21,F22,F23,F24,F25,F26,F27,F28\r\n",
      "FOODS_1_001_CA_1_validation,2,1,1,0,4,0,0,4,1,3,0,1,0,2,2,0,1,1,0,2,0,4,1,1,0,1,1,0\r\n"
     ]
    }
   ],
   "source": [
    "!head -n2 {submissions}/0200-naive.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T15:00:49.901629Z",
     "start_time": "2020-03-30T15:00:49.756887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,F1,F2,F3,F4,F5,F6,F7,F8,F9,F10,F11,F12,F13,F14,F15,F16,F17,F18,F19,F20,F21,F22,F23,F24,F25,F26,F27,F28\r\n",
      "HOBBIES_1_001_CA_1_validation,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\r\n"
     ]
    }
   ],
   "source": [
    "!head -n2 {raw}/sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T15:00:50.059809Z",
     "start_time": "2020-03-30T15:00:49.910296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   60981 submissions/0200-naive.csv\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l {submissions}/0200-naive.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-30T15:00:40.672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   60981 raw/sample_submission.csv\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l {raw}/sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-30T15:00:40.674Z"
    }
   },
   "outputs": [],
   "source": [
    "!open {submissions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-30T15:00:40.676Z"
    }
   },
   "outputs": [],
   "source": [
    "!open https://www.kaggle.com/c/m5-forecasting-accuracy/submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
